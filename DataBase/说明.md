# ------------文本生成------------
## AdvertiseGen广告文案生成数据集
https://www.luge.ai/#/luge/dataDetail?id=9
下载量 154
数据集大小 17.1M
### 数据集介绍
AdvertiseGen以商品网页的标签与文案的信息对应关系为基础构造，是典型的开放式生成任务，在模型基于key-value输入生成开放式文案时，与输入信息的事实一致性需要得到重点关注。
### 数据预览
任务描述：给定商品信息的关键词和属性列表kv-list，生成适合该商品的广告文案adv；
数据规模：训练集114k，验证集1k，测试集3k；
数据来源：清华大学CoAI小组；
数据样例：
```
{
  "content": "类型#上衣*材质#牛仔布*颜色#白色*风格#简约*图案#刺绣*衣样式#外套*衣款式#破洞",
  "summary": "简约而不简单的牛仔外套，白色的衣身十分百搭。衣身多处有做旧破洞设计，打破单调乏味，增加一丝造型看点。衣身后背处有趣味刺绣装饰，丰富层次感，彰显别样时尚。"
}
```
## LCSTS_new中文短摘要生成数据集
https://www.luge.ai/#/luge/dataDetail?id=10
下载量 141
数据集大小：263.1M
### 数据集介绍
LCSTS_new是中文短摘要最常用的LCSTS短摘要数据集的升级版本，在数据量、质量方面均有显著提升，在信息摘要与提炼的过程中，与原文的事实一致性需要得到重点关注。
### 数据预览
任务描述：给定文章正文doc，生成符合文章信息的摘要sum；
数据规模：训练集1500k，验证集 1k，测试集5k；
数据来源：LCSTS；
数据样例：
```
{
  "id": 6,
  "summary": "中国游客大增多国放宽签证",
  "content": "①北京和上海户籍的游客可获得韩国多次签证；②“整容客”可以不经由韩国使领馆、直接在网上申请签证；③中泰免签的实施日期尚未敲定；④越南已向中国持通行证旅游的公民全面开放。"
}
```
## DuReader_QG问题生成数据集
https://www.luge.ai/#/luge/dataDetail?id=8
下载量 119
数据集大小：6M
### 数据集介绍
DuReader robust旨在利用真实应用中的数据样本来衡量阅读理解模型的鲁棒性，评测模型的过敏感性、过稳定性以及泛化能力，是首个中文阅读理解鲁棒性数据集。
DuReader_QG是从DuReader robust中选择的问题生成任务子集
### 数据预览
任务描述：给定段落p和答案a，生成自然语言表述的问题q，且该问题符合段落和上下文的限制；
数据规模：训练集约14.5k，开发集约1k，测试集约1k；
数据样例：
```
{
  "context": "欠条是永久有效的,未约定还款期限的借款合同纠纷,诉讼时效自债权人主张债权之日起计算,时效为2年。 根据《中华人民共和国民法通则》第一百三十五条:向人民法院请求保护民事权利的诉讼时效期间为二年,法律另有规定的除外。 第一百三十七条:诉讼时效期间从知道或者应当知道权利被侵害时起计算。但是,从权利被侵害之日起超过二十年的,人民法院不予保护。有特殊情况的,人民法院可以延长诉讼时效期间。 第六十二条第(四)项:履行期限不明确的,债务人可以随时履行,债权人也可以随时要求履行,但应当给对方必要的准备时间。",
  "answer": "永久有效",
  "question": "欠条的有效期是多久",
  "id": 17
}
```
# ------------中文对话------------
## DuConv知识对话数据集
https://www.luge.ai/#/luge/dataDetail?id=30
下载量 2856
数据集大小：11M
特点：知识对话能力
### 数据集介绍
DuConv旨在考察模型是否可以在对话过程中充分利用外部知识(既包括结构化知识，也包括非结构化知识)，并且在生成对话回复的过程中引入外部知识，是首个bot主动的中文知识对话数据集。
## DuRecDial对话推荐数据集
https://www.luge.ai/#/luge/dataDetail?id=31
下载量：1439
数据集大小：13M
特点：对话推荐能力
### 数据集介绍
DuRecDial是首个融合多种对话类型的对话推荐数据集，它包含多种对话类型、多领域和丰富对话逻辑(考虑用户实时反馈)。在每个对话中，推荐者(bot)使用丰富的交互行为主动引导一个多类型对话不断接近推荐目标。DuRecDial旨在考察模型是否可以在对话过程中基于用户兴趣以及用户的实时反馈，主动给用户做出合理的推荐。
## LUGE-Dialogue开放域对话数据集合
https://www.luge.ai/#/luge/dataDetail?id=26
下载量：697
数据集大小：1.66G
特点：多技能领域
### 数据集介绍
本数据集旨在全面评测基于统一生成模型建模不同对话技能的整体效果，包括内容丰富度，多轮连贯性，知识准确率，对话主动性。
其中收集了一系列公开的开放域对话数据集，并对数据集进行了统一的整理以及提供了统一的评测方式，期望从多个技能、多个领域的角度对模型效果进行综合评价。该开源数据集旨在为研究人员和开发者提供学术和技术交流的平台，进一步提升开放域对话的研究水平，推动自然语言理解和人工智能领域技术的应用和发展。
同时，我们还收集并提供了开源的中文对话数据，参赛队可以基于这些对话数据构建自己的对话模型：
1.知识对话相关数据：百度的DuConv。
2.推荐对话相关数据：百度的DuRecDial。
3.画像对话数据：百度的画像数据集(DuPersona)。
4.其他对话数据：华为的微博数据，北航和微软的豆瓣多轮对话，清华的LCCC数据集，清华情感对话数据，腾讯的检索辅助生成对话数据集，清华的KdConv。
## Tencent中文开放域对话数据集
https://www.luge.ai/#/luge/dataDetail?id=36
下载量：260
数据集大小：543M
特点：闲聊能力
### 数据集介绍
Tencent是一个大规模的检索辅助生成的中文开放域对话数据集，旨在考察模型在闲聊场景中，是否可以生成流畅的、与上下文相关的对话回复。
## 微博开放域短文本对话数据集
https://www.luge.ai/#/luge/dataDetail?id=32
下载量：234
数据集大小：208M
特点：闲聊能力
### 数据集介绍
Weibo是一个大规模中文开放域短文本对话数据集，旨在考察模型在闲聊场景中，是否可以生成流畅的、与上下文相关的对话回复。
## KdConv中文知识对话数据集
https://www.luge.ai/#/luge/dataDetail?id=35
下载量：218
数据集大小：2.7M
特点:知识对话能力
### 数据集介绍
KdConv是一个多领域的中文知识对话数据集，旨在考察模型是否可以在对话过程中充分利用外部知识，并且在生成对话回复的过程中引入外部知识。

## LCCC开放域短文本对话数据集
闲聊数据集，考察模型在闲聊场景中，是否可以生成流畅的、与上下文相关的对话回复
https://www.luge.ai/#/luge/dataDetail?id=34
下载量：104
数据集大小：607M
特点：闲聊能力
### 数据集介绍
LCCC是一个大规模中文开放域短文本对话数据集，旨在考察模型在闲聊场景中，是否可以生成流畅的、与上下文相关的对话回复。

## 中文画像对话（Chinese Persona Chat）数据集
画像对话数据集，考察对话模型在闲聊场景中是否可以生成与给定画像一致的回复
https://www.luge.ai/#/luge/dataDetail?id=38
下载量：5
数据大小：38M
特点：对话人设能力
### 数据集介绍
画像对话数据集，考察对话模型在闲聊场景中是否可以生成符合对话历史和画像信息，且自然流畅、信息丰富的机器回复。

## Emotional STC （ESTC）情感对话数据集
情感对话数据集，考察模型是否可以在对话过程中充分利用情感信息，并生成具有正确情感倾向、且与上下文相关的对话回复
https://www.luge.ai/#/luge/dataDetail?id=37
数据集大小：
45M
特点：情感对话能力
### 数据集介绍
ECM是一个大规模的中文情感对话数据集，旨在考察模型是否可以在对话过程中充分利用情感信息，并生成具有正确情感倾向、且与上下文相关的对话回复。

# --------------阅读理解------------
## Dureaderchecklist阅读理解细粒度评估数据集
抽取式阅读理解数据集，从细粒度、多维度挑战机器理解语言的能力
https://www.luge.ai/#/luge/dataDetail?id=3
下载量：4562
数据集大小：18.7M
特点：checklist
### 数据集介绍
Dureader checklist建立了细粒度的、多维度的评测手段，从词汇理解、短语理解、语义角色理解、逻辑推理等多个维度检测模型的不足之处，从而推动阅读理解评测进入“精细化“时代。该数据集中的样本均来自于实际的应用场景，难度大，考察点丰富，覆盖了真实应用中诸多难以解决的问题。


## DuReaderrobust阅读理解鲁棒性数据集
抽取式阅读理解数据集，考察模型鲁棒性
https://www.luge.ai/#/luge/dataDetail?id=1
下载量：1380
数据集大小：20.9M
特点：鲁棒性
### 数据集介绍
DuReader robust旨在利用真实应用中的数据样本来衡量阅读理解模型的鲁棒性，评测模型的过敏
感性、过稳定性以及泛化能力，是首个中文阅读理解鲁棒性数据集。
## DuReaderyesno观点型阅读理解数据集
观点型阅读理解数据集 ，考察模型对观点极性的判断
https://www.luge.ai/#/luge/dataDetail?id=2
下载量：459
数据集大小：151.5M
### 数据集介绍
DuReader yesno是一个以观点极性判断为目标任务的数据集，可以弥补抽取类数据集评测指标的缺陷，从而更好地评价模型对观点极性的理解能力。

# ------------文本相似度--------------
## LCQMC通用领域问题匹配数据集
中文领域大规模问题匹配数据集
https://www.luge.ai/#/luge/dataDetail?id=14
下载量：3425
数据集大小：6.7M
特点：百度知道领域
### 数据集介绍
百度知道领域的中文问题匹配数据集，目的是为了解决在中文领域大规模问题匹配数据集的缺失。该数据集从百度知道不同领域的用户问题中抽取构建数据。

## OPPO小布对话文本语义匹配数据集
采样自智能对话场数据，考察问题匹配模型在对话意图理解能力
https://www.luge.ai/#/luge/dataDetail?id=28
下载量：3139
大小：10.8M
特点：智能对话场景
### 数据集介绍
通过对闲聊、智能客服、影音娱乐、信息查询等多领域真实用户交互语料进行用户信息脱敏、相似度筛选处理得到，数据集主要特点是文本较短、非常口语化、存在文本高度相似而语义不同的难例。该数据集所有标签都有经过人工精标确认。

## BQ金融领域问题匹配数据集
金融领域数据集，考察模型在金融领域上的能力
https://www.luge.ai/#/luge/dataDetail?id=15
下载量：758
大小：4.2M
特点：银行金融领域
### 数据集介绍
银行金融领域的问题匹配数据，包括了从一年的线上银行系统日志里抽取的问题pair对，是目前最大的银行领域问题匹配数据。

## DuQM细粒度鲁棒性问题匹配数据集
问题匹配评测集合，考察模型在实际应用中的鲁棒性
https://www.luge.ai/#/luge/dataDetail?id=27
下载量：2052
大小：920k
特点：鲁棒性测试
### 数据集介绍
DuQM评测集关注问题匹配模型在真实应用场景中的鲁棒性，从词汇理解、句法结构、错别字、口语化四个维度检测模型的能力，从而发现模型的不足之处，推动语义匹配技术的发展。

## PAWS语序对抗问题匹配数据集
词汇高度重合，考察模型对句法结构的理解能力
https://www.luge.ai/#/luge/dataDetail?id=16
下载量：667
大小：2.9M
特点：考察句法结构
### 数据集介绍
数据集里包含了释义对和非释义对，即识别一对句子是否具有相同的释义（含义），特点是具有高度重叠词汇，重点考察模型对句法结构的理解能力。

# ------------情感分析------------
## ChnSentiCorp句子级情感分类数据集
https://www.luge.ai/#/luge/dataDetail?id=25
下载量：3628
大小：1.9M
### 数据集介绍
经典的句子级情感分类数据集，包含酒店、笔记本电脑和数据相关的网络评论数据，共包含积极、消极两个类别。

## SE-ABSA16观点级情感分类数据集
https://www.luge.ai/#/luge/dataDetail?id=18
下载量：1532
大小：764k
### 数据集介绍
观点级情感分类是一种细粒度的情感分类任务，旨在评论分本中针对不同评价对象或者评论维度的情感分类。该数据集包含积极、消极两个类别。共覆盖手机、相机两个领域的数据。

## COTE中文观点抽取数据集
https://www.luge.ai/#/luge/dataDetail?id=19
下载量：1350
大小：10.3M
特点：评价对象抽取
### 数据集介绍
评价对象抽取任务旨在对于给定的评论文本，自动抽取其中包含的评价对象。该任务是情感分析中的基础任务之一，该数据集覆盖百度、点评和马蜂窝上抓取的数据。
## NLPCC14-SC情感分类评测数据集
https://www.luge.ai/#/luge/dataDetail?id=20
下载量：431
大小：1.2M
特点:句子级情感分析
### 数据集介绍
该数据集来自NLPCC 2014 情感分类评测任务数据集，旨在评估深度学习方法在情感分类任务上的效果，数据集覆盖多个领域（例如：书籍、DVD、电子等），共包含积极、消极两个类别。

## ASAP中文评论分析数据集
https://www.luge.ai/#/luge/dataDetail?id=17
下载量：250
大小：46M
特点：真实电商场景
### 数据集介绍
业界最大规模中文评论分析数据集ASAP，首次实现对评论得分预估和对象级情感分类两个任务的联合标注，数据全部源于真实的电商场景，从数据规模和标注质量上都远超其他数据集。
## DuVideoSenti多模态情感标签数据集
https://www.luge.ai/#/luge/dataDetail?id=21
下载量：141
大小：11.1G
特点：多模态情感分析
### 数据集介绍
面向推荐场景推出多模态情感标签数据集DuVideoSenti，引入视频情感泛标签预测任务，构建了视频情感泛标签体系。该体系由人工定义的“文艺清新”、“时尚炫酷”、“舒适温馨”等11个情感泛标签组成，用以刻画用户浏览视频后的视觉和情感方面的感受。数据集为每个小视频标注了情感泛标签，并且提供了视频的标题、帧图特征用于模型的训练和预测。
## SENTI_ROBUST中文情感鲁棒性数据集
https://www.luge.ai/#/luge/dataDetail?id=23
下载量：95
大小：0.9M
特点：情感鲁棒性
### 数据集介绍
“可信AI”的概念在近几年提出，并且逐渐成为全球共识。可信AI，就是保证AI系统的可解释性、鲁棒性和公平性，确保算法可被人信任。在情感分析技术的科学研究和产业落地中，可信情感分析系统需要具备较强的鲁棒性和可解释能力，也就是要求模型针对各种不同表达，既能给出精准的预测结果，还能给出其判断依据，从而保证模型的预测结果更加置信。
作为业界首个中文情感可信数据集，DuTrust基于人工标注的扰动数据和情感证据，全部来源于真实用户评论数据，同时测试模型的鲁棒性和可解释性，全面评估模型的可信能力。
## SENTI_RATIONAL情感可解释性数据集
https://www.luge.ai/#/luge/dataDetail?id=22
下载量：88
大小：0.9M
特点：情感可解释性
### 数据集介绍
“可信AI”的概念在近几年提出，并且逐渐成为全球共识。可信AI，就是保证AI系统的可解释性、鲁棒性和公平性，确保算法可被人信任。在情感分析技术的科学研究和产业落地中，可信情感分析系统需要具备较强的鲁棒性和可解释能力，也就是要求模型针对各种不同表达，既能给出精准的预测结果，还能给出其判断依据，从而保证模型的预测结果更加置信。
作为业界首个中文情感可信数据集，DuTrust基于人工标注的扰动数据和情感证据，全部来源于真实用户评论数据，同时测试模型的鲁棒性和可解释性，全面评估模型的可信能力。

# -----------------语义解析----------------------
## DuSQL-中文多表SQL解析数据集
跨领域多表中文数据集，考察模型领域迁移泛化能力、推理能力
https://www.luge.ai/#/luge/dataDetail?id=13
下载量：1979
大小：2.8M
特点：跨领域复杂
### 数据集介绍
DuSQL是一个面向实际应用的数据集，包含200个数据库，覆盖了164个领域，问题覆盖了匹配、计算、推理等实际应用中常见形式。该数据集更贴近真实应用场景，要求模型领域无关、问题无关，且具备计算推理等能力。

## NL2SQL-中文单表SQL解析数据集
跨领域单表中文数据集，考察模型领域迁移泛化能力
https://www.luge.ai/#/luge/dataDetail?id=12
下载量：500
大小：22.4M
特点：跨领域简单
### 数据集介绍
NL2SQL是一个多领域的简单数据集，其主要包含匹配类型问题。该数据集主要验证模型的泛化能力，其要求模型具有较强的领域泛化能力、问题泛化能力。
## Cspider-中英文多表SQL解析数据集
跨领域多表数据集，考察模型领域迁移泛化能力、多语言处理能力
https://www.luge.ai/#/luge/dataDetail?id=11
下载量：462
大小：36.5M
特点：跨领域多语言
### 数据集介绍
CSpider是一个多语言数据集，其问题以中文表达，数据库以英文存储，这种双语模式在实际应用中也非常常见，尤其是数据库引擎对中文支持不好的情况下。该数据集要求模型领域无关、问题无关，且能够实现多语言匹配。
# -----------机器同传---------------
## BSTC中译英语音翻译数据集
到目前为止（2021.11）最大的中译英语音翻译数据集，可用来考察机器同传模型的翻译-延时效果
https://www.luge.ai/#/luge/dataDetail?id=4
下载量：334
大小：5.6G
特点：大规模
### 数据集介绍
BSTC数据集是一个大规模中译英语音翻译数据集，它包括一系列授权了的中文演讲视频（68小时）及其对应的转录文本和翻译文本（英语），弥补了已有语音翻译数据集在中文视频上的缺陷。
# --------------信息抽取----------------------
## DuIE2.0中文关系抽取数据集
业界规模最大的中文关系抽取数据集，考察schema约束下的关系抽取能力
https://www.luge.ai/#/luge/dataDetail?id=5
下载量：2859
大小：38.6M
### 数据集介绍
DuIE2.0是业界规模最大的中文关系抽取数据集，其schema在传统简单关系类型基础上添加了多元复杂关系类型，此外其构建语料来自百度百科、百度信息流及百度贴吧文本，全面覆盖书面化表达及口语化表达语料，能充分考察真实业务场景下的关系抽取能力。
## DuEE1.0中文事件抽取数据集
事件抽取数据集，考察模型对事件知识的分析能力
https://www.luge.ai/#/luge/dataDetail?id=6
下载量：2481
大小：5.8M
### 数据集介绍
DuEE1.0是百度发布的中文事件抽取数据集，包含65个事件类型的1.7万个具有事件信息的句子（2万个事件）。事件类型根据百度风云榜的热点榜单选取确定，具有较强的代表性。65个事件类型中不仅包含「结婚」、「辞职」、「地震」等传统事件抽取评测中常见的事件类型，还包含了「点赞」等极具时代特征的事件类型。数据集中的句子来自百度信息流资讯文本，相比传统的新闻资讯，文本表达自由度更高，事件抽取的难度也更大。

## DuEE-fin金融领域篇章级事件抽取数据集
金融领域篇章级事件抽取数据集，考察模型对长文本的事件知识分析
https://www.luge.ai/#/luge/dataDetail?id=7
下载量：2007
大小：39.9M
### 数据集介绍
DuEE-fin是百度最新发布的金融领域篇章级事件抽取数据集，包含13个事件类型的1.17万个篇章，同时存在部分非目标篇章作为负样例。事件类型来源于常见的金融事件，数据集中的篇章来自金融领域的新闻和公告，覆盖了真实应用场景中诸多难以解决的问题。
# ---------------实体链指---------------
## DuEL 2.0中文短文本实体链指数据集
旨在借助实体链指技术，拓展其对应的AI智能应用需求，并将技术成果实践于更多的现实场景
https://www.luge.ai/#/luge/dataDetail?id=24
下载量：185
大小：61.3
### 数据集介绍
DuEL 2.0 是一个以中文短文本实体链接为目标任务的数据集。该数据集中的样本主要来自于搜索Query、微博、对话内容、标题等，样本的口语化严重，上下文语境不丰富，难度较大。此外，DuEL2.0数据集具有如下特点：

1、大规模：7万训练集、1万开发集、1万测评集32.4万知识库实体，282.6万SPO；

2、高质量：所有标注数据通过人工众包完成，实体链指及实体类型准确率达95%，知识库实体重复率小于5%；

3、面向真实场景：数据来自于互联网网页标题、UGC短视频标题、搜索Query。

# -----------------自然语言推理------------------
## 中文成语语义推理数据集(CINLID)
中文成语语义推理数据集，可用于测试模型的非字面义语义理解能力
https://www.luge.ai/#/luge/dataDetail?id=39
下载量：50
大小：14.2M
### 数据集介绍
计算词/词组、句子、段落和文档之间的语义相似性（STS，Semantic similarity of text）在自然语言处理和计算语言学中起着重要作用，是一个非常重要的任务。
语义相似性中的条目（词、短语、句等）之间的距离概念是基于其意义或语义内容的相似性，而不是词汇学的相似性。基于字面含义的“望文生义”在做NLP相关任务时很容易出现问题，如传统测度文本相似度的方法经常会把“目不识丁”和“目中无人”的相似度算得很高。但它们的语义明显是不相关的；又比如“孤芳自赏”和“师心自用”都有“自负、骄傲”的含义，语义相似度较高，但一般传统的文本相似度计算方法很难将它们的内在语义相似性准确的捕捉到。
为了得到良好的语句表示，我们需要一个能编码基础语义关系的语料，而且字面重叠的情况要少，让机器学习的难度更大些，以便学到更多有用的语义信息。因此，我们基于同一关系、包含关系、重叠关系、分离关系这4种基本的语义类别构建了中文成语语义推理数据集（Chinese Idioms Natural Language Inference Dataset）。


